{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x = torch.Tensor([[1,2],[3,4]])\n",
    "x = torch.from_numpy(np.array([[1,2],[3,4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[연산 전]\n",
      "\n",
      "\n",
      "tensor([[5.3129e-08, 4.1961e-08],\n",
      "        [2.1971e-04, 6.6820e+22]]) \n",
      "\n",
      "tensor([[-9.8173e-11,  3.0914e-41],\n",
      "        [-2.4031e+23,  4.5839e-41]]) \n",
      "\n",
      "[연산 후]\n",
      "\n",
      "\n",
      "tensor([[5.3129e-08, 4.1961e-08],\n",
      "        [2.1971e-04, 6.6820e+22]]) \n",
      "\n",
      "tensor([[-9.8173e-11,  3.0914e-41],\n",
      "        [-2.4031e+23,  4.5839e-41]], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[연산 전]\\n\\n\")\n",
    "\n",
    "x = torch.FloatTensor(2,2)\n",
    "print(x,\"\\n\")\n",
    "y = torch.FloatTensor(2,2)\n",
    "print(y,\"\\n\")\n",
    "y.requires_grad_(True)\n",
    "\n",
    "print(\"[연산 후]\\n\\n\")\n",
    "z = (x+y) + torch.FloatTensor(2,2)\n",
    "print(x,\"\\n\")\n",
    "print(y,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[연산 전]\n",
      "\n",
      "\n",
      "tensor([[-2.4031e+23,  4.5839e-41],\n",
      "        [-2.4031e+23,  4.5839e-41]]) \n",
      "\n",
      "tensor([[-2.4031e+23,  4.5839e-41],\n",
      "        [-2.4031e+23,  4.5839e-41]]) \n",
      "\n",
      "[연산 후]\n",
      "\n",
      "\n",
      "tensor([[-2.4031e+23,  4.5839e-41],\n",
      "        [-2.4031e+23,  4.5839e-41]]) \n",
      "\n",
      "tensor([[-2.4031e+23,  4.5839e-41],\n",
      "        [-2.4031e+23,  4.5839e-41]], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[연산 전]\\n\\n\")\n",
    "\n",
    "x = torch.FloatTensor(2,2)\n",
    "print(x,\"\\n\")\n",
    "y = torch.FloatTensor(2,2)\n",
    "print(y,\"\\n\")\n",
    "y.requires_grad_(True)\n",
    "\n",
    "print(\"[연산 후]\\n\\n\")\n",
    "\n",
    "with torch.no_grad() :\n",
    "    z = (x+y) + torch.FloatTensor(2,2)\n",
    "print(x,\"\\n\")\n",
    "print(y,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5])\n"
     ]
    }
   ],
   "source": [
    "def linear(x,W,b) : \n",
    "    y = torch.mm(x,W) + b\n",
    "    return y\n",
    "\n",
    "x = torch.FloatTensor(16,10)\n",
    "W = torch.FloatTensor(10,5)\n",
    "b = torch.FloatTensor(5)\n",
    "\n",
    "y = linear(x,W,b)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyLinear(nn.Module) :\n",
    "    \n",
    "    def __init__(self, input_size, output_size) :\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = torch.FloatTensor(input_size, output_size)\n",
    "        self.b = torch.FloatTensor(output_size)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "        return y      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[        nan,         nan,         nan,         nan,         nan],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [ 1.4397e+26, -2.7430e-38,  5.8250e-08, -1.8489e-38,  5.8251e-08],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [ 2.9450e-10, -1.2356e+21,  2.9448e-10,  1.7778e-14,  1.4396e+26],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [-9.7688e-11, -6.4279e-18,  2.2128e+13,  5.1337e-19,  1.4462e+12],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [-9.7688e-11,  3.0914e-41,  2.2228e-01,  3.0914e-41, -9.7675e-11],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [ 1.4375e+26, -2.7388e-38,  5.8161e-08, -1.8461e-38,  5.8161e-08],\n",
      "        [-9.7688e-11, -1.1016e-17, -9.7709e-11,  3.0914e-41,  1.4374e+26],\n",
      "        [-9.7688e-11,  3.0914e-41, -9.7709e-11,  3.0914e-41, -9.7675e-11],\n",
      "        [-9.7688e-11,  3.0914e-41, -9.7709e-11,  3.0914e-41, -9.7675e-11]])\n",
      "torch.Size([16, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(16,10)\n",
    "linear = MyLinear(10,5)\n",
    "y = linear(x)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyLinear(nn.Module) :\n",
    "    \n",
    "    def __init__(self, input_size, output_size) :\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = nn.Parameter(torch.FloatTensor(input_size, output_size), requires_grad = True)\n",
    "        self.b = nn.Parameter(torch.FloatTensor(output_size), requires_grad = True)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "        return y      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[        nan,         nan,         nan,         nan,         nan],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [-4.3696e+25, -1.0169e+25, -6.6216e+26, -1.6653e+23,  5.9362e-08],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [-4.3789e+11, -1.0191e+11, -6.6356e+12, -1.6689e+09,  1.3623e-19],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [-9.7775e-11,  2.1210e-18, -9.7539e-11,  3.0914e-41,  5.8689e-08],\n",
      "        [        nan,         nan,         nan,         nan,         nan],\n",
      "        [ 1.4437e+26, -2.7508e-38,  5.8816e-08, -1.8541e-38,  5.9345e-08],\n",
      "        [-9.7775e-11,  7.1159e-23, -9.7686e-11,  1.1653e-24,  8.9683e-44],\n",
      "        [ 1.4468e+12, -8.1886e-06, -4.9368e+20, -8.0601e-17, -8.0718e-17],\n",
      "        [ 5.8707e-08,  3.1450e-18,  5.8707e-08, -1.8367e-38,  1.3563e-19],\n",
      "        [-9.7775e-11,  3.0914e-41, -9.7686e-11,  3.0914e-41,  8.9683e-44],\n",
      "        [-9.7775e-11,  3.0914e-41, -9.7686e-11,  3.0914e-41,  8.9683e-44],\n",
      "        [-4.3286e+25, -1.0074e+25, -6.5594e+26, -1.6497e+23,  5.8805e-08]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([16, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(16,10)\n",
    "linear = MyLinear(10,5)\n",
    "y = linear(x)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([10, 5]), torch.Size([5])]\n"
     ]
    }
   ],
   "source": [
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyLinear(nn.Module) :\n",
    "    \n",
    "    def __init__(self, input_size, output_size) :\n",
    "        super(MyLinear,self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        y = self.linear(x)\n",
    "        return y      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyLinear(\n",
      "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n",
      "[torch.Size([5, 10]), torch.Size([5])]\n"
     ]
    }
   ],
   "source": [
    "linear = MyLinear(10,5)\n",
    "print(linear)\n",
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0855, -0.1788, -0.0367,  0.2139,  0.0017,  0.1289, -0.2166,  0.0341,\n",
      "         -0.0184, -0.1835],\n",
      "        [ 0.2370,  0.2234,  0.0955,  0.1342, -0.0801, -0.0362, -0.0824,  0.0273,\n",
      "          0.1263, -0.1121],\n",
      "        [-0.2807,  0.1307, -0.2213, -0.2724,  0.1343,  0.1144,  0.0141, -0.2057,\n",
      "          0.1483, -0.2492],\n",
      "        [-0.1546, -0.2279, -0.2016, -0.2175,  0.1029,  0.2460,  0.1697,  0.3103,\n",
      "          0.1640,  0.2083],\n",
      "        [-0.2927,  0.2663, -0.0531, -0.2704,  0.0948,  0.2082, -0.0278,  0.0515,\n",
      "          0.2238,  0.0179]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1908, -0.1352, -0.3060, -0.0046,  0.1296], requires_grad=True)]\n",
      "[Parameter containing:\n",
      "tensor([[-0.0855, -0.1788, -0.0367,  0.2139,  0.0017,  0.1289, -0.2166,  0.0341,\n",
      "         -0.0184, -0.1835],\n",
      "        [ 0.2370,  0.2234,  0.0955,  0.1342, -0.0801, -0.0362, -0.0824,  0.0273,\n",
      "          0.1263, -0.1121],\n",
      "        [-0.2807,  0.1307, -0.2213, -0.2724,  0.1343,  0.1144,  0.0141, -0.2057,\n",
      "          0.1483, -0.2492],\n",
      "        [-0.1546, -0.2279, -0.2016, -0.2175,  0.1029,  0.2460,  0.1697,  0.3103,\n",
      "          0.1640,  0.2083],\n",
      "        [-0.2927,  0.2663, -0.0531, -0.2704,  0.0948,  0.2082, -0.0278,  0.0515,\n",
      "          0.2238,  0.0179]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1908, -0.1352, -0.3060, -0.0046,  0.1296], requires_grad=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deokyoung/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "objective = 100\n",
    "\n",
    "x = torch.FloatTensor(16,10)\n",
    "linear = MyLinear(10,5)\n",
    "y = linear(x)\n",
    "\n",
    "\n",
    "params = [ parm for parm in linear.parameters()]\n",
    "\n",
    "print(params)\n",
    "\n",
    "# print(y.sum())\n",
    "\n",
    "loss = torch.pow(objective - y.sum(),2)\n",
    "\n",
    "# print(loss)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "params = [ parm for parm in linear.parameters()]\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train, Eval\n",
    "\n",
    "- 평가모드, train모드 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLinear(\n",
       "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLinear(\n",
       "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. [example] linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class MyModel(nn.Module) :\n",
    "    \n",
    "    def __init__(self, input_size, output_size) :\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self,x) :\n",
    "        y = self.linear(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth(x) : \n",
    "    return 3 * x[:,0] + x[:,1]-2*x[:,2]\n",
    "\n",
    "def train(model, x, y, optim) :\n",
    "\n",
    "    optim.zero_grad()\n",
    "\n",
    "    y_hat = model(x)\n",
    "\n",
    "    loss = ((y-y_hat)**2).sum() / x.size(0)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optim.step()\n",
    "    \n",
    "    return loss.data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "n_epochs = 2\n",
    "n_iter = 1\n",
    "\n",
    "model = MyModel(3,1)\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-4, momentum= 0.1)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for epoch in range(n_epochs) : \n",
    "    avg_loss =0\n",
    "    \n",
    "    for i in range(n_iter) :\n",
    "        x = torch.rand(batch_size, 3)\n",
    "        y = ground_truth(x.data)\n",
    "        \n",
    "        loss = train(model, x, y, optim)\n",
    "        \n",
    "        avg_loss += loss\n",
    "    avg_loss = avg_loss / n_iter\n",
    "    \n",
    "    x_valid = torch.FloatTensor([[.3,.2,.1]])\n",
    "    y_valid = ground_truth(x_valid.data)\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat = model(x_valid)\n",
    "    model.train()\n",
    "    \n",
    "    print(\"epoch\",epoch,\":\",avg_loss, y_valid.data[0], y_hat.data[0,0])\n",
    "    \n",
    "    if avg_loss < 0.001 :\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0551, -0.0026,  0.1201]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2168], requires_grad=True)]\n",
      "[Parameter containing:\n",
      "tensor([[-0.0547, -0.0024,  0.1203]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2173], requires_grad=True)]\n",
      "epoch 0 : tensor(5.2176) tensor(0.9000) tensor(0.2124)\n",
      "[Parameter containing:\n",
      "tensor([[-0.0547, -0.0024,  0.1203]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2173], requires_grad=True)]\n",
      "[Parameter containing:\n",
      "tensor([[-0.0543, -0.0021,  0.1204]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2178], requires_grad=True)]\n",
      "epoch 1 : tensor(5.4879) tensor(0.9000) tensor(0.2131)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs) : \n",
    "    avg_loss =0\n",
    "    \n",
    "    for i in range(n_iter) :\n",
    "        x = torch.rand(batch_size, 3)\n",
    "        y = ground_truth(x.data)\n",
    "        \n",
    "        params = [ parm for parm in model.parameters()]\n",
    "        print(params)\n",
    "        \n",
    "        loss = train(model, x, y, optim)\n",
    "        \n",
    "        params = [ parm for parm in model.parameters()]\n",
    "        print(params)\n",
    "        \n",
    "        \n",
    "        \n",
    "        avg_loss += loss\n",
    "    avg_loss = avg_loss / n_iter\n",
    "    \n",
    "    x_valid = torch.FloatTensor([[.3,.2,.1]])\n",
    "    y_valid = ground_truth(x_valid.data)\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat = model(x_valid)\n",
    "    model.train()\n",
    "    \n",
    "    print(\"epoch\",epoch,\":\",avg_loss, y_valid.data[0], y_hat.data[0,0])\n",
    "    \n",
    "    if avg_loss < 0.001 :\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([.3,.2,.1]).size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.3000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable \n",
    "\n",
    "x = torch.FloatTensor([[.1,.2,.3]])\n",
    "Variable(x, volatile = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autograd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
